<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Turn Detection Voice Transcription</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <link rel="stylesheet" href="static/styles.css" />
    </head>
    <body
        class="bg-gradient-to-br from-gray-900 via-purple-900 to-gray-900 text-white min-h-screen"
    >
        <div class="container mx-auto p-4 h-screen flex flex-col">
            <div class="flex justify-center flex-1 min-h-0">
                <div
                    class="bg-white/10 backdrop-blur-xl rounded-3xl border border-white/20 shadow-2xl max-w-4xl w-full flex flex-col h-full"
                >
                    <!-- Header -->
                    <div
                        class="p-4 border-b border-white/10 flex justify-between items-center flex-shrink-0"
                    >
                        <div>
                            <h1
                                class="text-3xl font-extrabold bg-gradient-to-r from-purple-400 to-blue-400 bg-clip-text text-transparent mb-2 select-none tracking-wide"
                            >
                                üéôÔ∏è Turn Detection Transcription
                            </h1>
                            <p class="text-slate-300 text-sm ml-2">
                                Speak and pause - transcription appears when
                                stop talking
                            </p>
                        </div>
                        <div class="flex flex-col items-end gap-2">
                            <div
                                id="connectionStatus"
                                class="text-sm font-bold tracking-wide bg-white/10 backdrop-blur-lg p-2 rounded-full shadow-lg border border-white/20"
                            >
                                <span class="text-red-300">‚óè Disconnected</span>
                            </div>
                            <div
                                id="listeningStatus"
                                class="text-xs bg-gray-700/50 p-2 rounded-lg border border-gray-600/50 hidden"
                            >
                                <span class="text-gray-300"
                                    >üé§ Listening...</span
                                >
                            </div>
                        </div>
                    </div>

                    <!-- Real-time Status -->
                    <div class="px-6 py-3 bg-white/5 border-b border-white/10">
                        <div
                            id="realTimeStatus"
                            class="text-center text-sm text-gray-400"
                        >
                            Ready to detect speech turns
                        </div>
                        <div
                            id="interimText"
                            class="text-center text-sm text-blue-300 italic mt-1 min-h-[20px]"
                        >
                            <!-- Interim text appears here -->
                        </div>
                    </div>

                    <!-- Transcription Display -->
                    <div
                        id="transcriptionContainer"
                        class="flex-1 p-6 overflow-y-auto space-y-4 min-h-0"
                        style="max-height: calc(100vh - 350px)"
                    >
                        <div class="text-center text-gray-400 mt-8">
                            <p>
                                Click "Start Recording" and speak. Transcription
                                will appear when you stop talking.
                            </p>
                            <p class="text-xs mt-2 text-gray-500">
                                Turn detection waits for 500ms of silence to
                                complete a turn
                            </p>
                        </div>
                    </div>

                    <!-- Controls -->
                    <div
                        class="p-3 border-t border-white/10 bg-white/5 rounded-3xl rounded-t-none flex-shrink-0"
                    >
                        <div class="text-center mb-4">
                            <h3 class="text-lg font-semibold text-white mb-1">
                                Turn Detection Controls
                            </h3>
                            <p class="text-gray-300 text-sm">
                                Automatic turn detection - speak and pause
                            </p>
                        </div>
                        <div class="flex justify-center gap-4 mb-4">
                            <button
                                id="startBtn"
                                class="bg-gradient-to-r from-green-500 to-green-600 hover:from-green-600 hover:to-green-700 text-white font-semibold py-3 px-6 rounded-xl shadow-lg flex items-center gap-2 transition-all duration-200"
                            >
                                <div
                                    class="w-3 h-3 bg-white rounded-full"
                                ></div>
                                Start Turn Detection
                            </button>
                            <button
                                id="stopBtn"
                                class="bg-gradient-to-r from-red-500 to-red-600 hover:from-red-600 hover:to-red-700 text-white font-semibold py-3 px-6 rounded-xl shadow-lg flex items-center gap-2 opacity-50 cursor-not-allowed transition-all duration-200"
                                disabled
                            >
                                <div class="w-3 h-3 bg-white rounded-sm"></div>
                                Stop Detection
                            </button>
                            <button
                                id="clearBtn"
                                class="bg-gradient-to-r from-gray-600 to-gray-700 hover:from-gray-700 hover:to-gray-800 text-white font-semibold py-3 px-6 rounded-xl shadow-lg flex items-center gap-2 transition-all duration-200"
                            >
                                <svg
                                    class="w-4 h-4"
                                    fill="none"
                                    stroke="currentColor"
                                    viewBox="0 0 24 24"
                                >
                                    <path
                                        stroke-linecap="round"
                                        stroke-linejoin="round"
                                        stroke-width="2"
                                        d="M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16"
                                    ></path>
                                </svg>
                                Clear
                            </button>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <footer class="text-center py-4 flex-shrink-0">
            <p class="text-gray-400 text-sm">
                Powered by
                <span class="text-purple-400 font-semibold">FastAPI</span> &
                <span class="text-green-400 font-semibold">AssemblyAI</span>
            </p>
        </footer>
        <!-- <script src="/static/script.js"></script> -->
        <script>
            let websocket = null;
            let audioContext = null;
            let audioWorkletNode = null;
            let audioStream = null;
            let isRecording = false;
            let turnCount = 0;

            let startBtn,
                stopBtn,
                clearBtn,
                connectionStatus,
                listeningStatus,
                realTimeStatus,
                interimText,
                transcriptionContainer;

            // Connect to WebSocket
            function connectWebSocket() {
                const wsUrl = `ws://${window.location.host}/ws`;
                console.log("Attempting to connect to WebSocket:", wsUrl);

                websocket = new WebSocket(wsUrl);

                websocket.onopen = () => {
                    console.log("WebSocket connected");
                    connectionStatus.innerHTML =
                        '<span class="text-green-300">‚óè Connected</span>';
                    addSystemMessage(
                        "Connected to turn detection server",
                        "success"
                    );

                    // Test interim text element
                    interimText.textContent =
                        "Connection test - interim text working";
                    setTimeout(() => {
                        interimText.textContent = "";
                    }, 2000);
                };

                websocket.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    handleWebSocketMessage(data);
                };

                websocket.onclose = () => {
                    console.log("WebSocket disconnected");
                    connectionStatus.innerHTML =
                        '<span class="text-red-300">‚óè Disconnected</span>';
                    addSystemMessage("Disconnected from server", "error");
                };

                websocket.onerror = (error) => {
                    console.error("WebSocket error:", error);
                    connectionStatus.innerHTML =
                        '<span class="text-red-300">‚óè Error</span>';
                    addSystemMessage("Connection error", "error");
                };
            }

            function handleWebSocketMessage(data) {
                switch (data.type) {
                    case "connection":
                        addSystemMessage(data.message, "info");
                        break;
                    case "status":
                        addSystemMessage(data.message, "info");
                        if (data.message.includes("started")) {
                            realTimeStatus.textContent =
                                "Listening for speech... Speak and pause to see results";
                            listeningStatus.classList.remove("hidden");
                        }
                        break;
                    case "interim_transcript":
                        // Show interim results in the status area
                        console.log("Received interim transcript:", data.text);
                        interimText.textContent = `Speaking: "${data.text}"`;
                        realTimeStatus.textContent = "Processing speech...";
                        break;
                    case "turn_end":
                        // Turn ended - display final transcript
                        addTurnTranscript(data.text);
                        interimText.textContent = "";
                        realTimeStatus.textContent =
                            "Turn completed. Listening for next turn...";
                        break;
                    case "turn_update":
                        // Update the last turn with better formatted text
                        updateLastTurnTranscript(data.text);
                        break;
                    case "error":
                        addSystemMessage(data.message, "error");
                        break;
                }
            }

            function updateLastTurnTranscript(newText) {
                // Find the last turn card and update its text
                const lastCard = transcriptionContainer.lastElementChild;
                if (lastCard && lastCard.querySelector(".transcript-text")) {
                    lastCard.querySelector(".transcript-text").textContent =
                        newText;
                    console.log(`Updated last turn with: ${newText}`);
                }
            }

            // Audio processing worklet
            const audioWorkletCode = `
        class AudioProcessor extends AudioWorkletProcessor {
            constructor() {
                super();
                this.bufferSize = 1600; // 100ms at 16kHz
                this.buffer = new Float32Array(this.bufferSize);
                this.bufferIndex = 0;
            }

            process(inputs, outputs, parameters) {
                const input = inputs[0];
                if (input.length > 0) {
                    const inputChannel = input[0];
                    
                    for (let i = 0; i < inputChannel.length; i++) {
                        this.buffer[this.bufferIndex] = inputChannel[i];
                        this.bufferIndex++;
                        
                        if (this.bufferIndex >= this.bufferSize) {
                            // Convert to 16-bit PCM
                            const pcmData = new Int16Array(this.bufferSize);
                            for (let j = 0; j < this.bufferSize; j++) {
                                const sample = Math.max(-1, Math.min(1, this.buffer[j]));
                                pcmData[j] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                            }
                            
                            // Send PCM data
                            this.port.postMessage(pcmData.buffer);
                            
                            // Reset buffer
                            this.bufferIndex = 0;
                        }
                    }
                }
                return true;
            }
        }

        registerProcessor('audio-processor', AudioProcessor);
        `;

            async function startRecording() {
                try {
                    // Get audio stream
                    audioStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                        },
                    });

                    // Create audio context
                    audioContext = new AudioContext({ sampleRate: 16000 });

                    // Create worklet
                    const workletBlob = new Blob([audioWorkletCode], {
                        type: "application/javascript",
                    });
                    const workletUrl = URL.createObjectURL(workletBlob);

                    await audioContext.audioWorklet.addModule(workletUrl);
                    audioWorkletNode = new AudioWorkletNode(
                        audioContext,
                        "audio-processor"
                    );

                    // Create source and connect
                    const source =
                        audioContext.createMediaStreamSource(audioStream);
                    source.connect(audioWorkletNode);

                    // Handle audio data
                    audioWorkletNode.port.onmessage = (event) => {
                        if (
                            websocket &&
                            websocket.readyState === WebSocket.OPEN &&
                            isRecording
                        ) {
                            websocket.send(event.data);
                        }
                    };

                    // Send start command
                    websocket.send(
                        JSON.stringify({ command: "start_recording" })
                    );

                    isRecording = true;
                    updateButtonStates();
                } catch (error) {
                    console.error("Error starting recording:", error);
                    addSystemMessage(
                        "Failed to start recording: " + error.message,
                        "error"
                    );
                }
            }

            function stopRecording() {
                if (isRecording) {
                    // Send stop command
                    websocket.send(
                        JSON.stringify({ command: "stop_recording" })
                    );

                    // Clean up audio resources
                    if (audioWorkletNode) {
                        audioWorkletNode.disconnect();
                        audioWorkletNode = null;
                    }

                    if (audioContext) {
                        audioContext.close();
                        audioContext = null;
                    }

                    if (audioStream) {
                        audioStream
                            .getTracks()
                            .forEach((track) => track.stop());
                        audioStream = null;
                    }

                    isRecording = false;
                    updateButtonStates();
                    realTimeStatus.textContent = "Turn detection stopped";
                    interimText.textContent = "";
                    listeningStatus.classList.add("hidden");
                }
            }

            function clearTranscripts() {
                transcriptionContainer.innerHTML =
                    '<div class="text-center text-gray-400 mt-8"><p>Transcripts cleared - start recording again</p></div>';
                turnCount = 0;
                realTimeStatus.textContent = "Ready to detect speech turns";
                interimText.textContent = "";
            }

            function updateButtonStates() {
                startBtn.disabled = isRecording;
                stopBtn.disabled = !isRecording;

                startBtn.classList.toggle("opacity-50", isRecording);
                stopBtn.classList.toggle("opacity-50", !isRecording);
                startBtn.classList.toggle("cursor-not-allowed", isRecording);
                stopBtn.classList.toggle("cursor-not-allowed", !isRecording);
            }

            function addTurnTranscript(text) {
                if (turnCount === 0) {
                    transcriptionContainer.innerHTML = "";
                }

                turnCount++;

                // Create turn transcript
                const transcriptElement = document.createElement("div");
                transcriptElement.className = "mb-4 animate-fadeIn";
                transcriptElement.innerHTML = `
                <div class="bg-gradient-to-r from-green-500/20 to-blue-500/20 rounded-2xl p-4 border border-green-500/30">
                    <div class="flex items-start gap-3">
                        <div class="w-8 h-8 bg-gradient-to-r from-green-500 to-blue-500 rounded-full flex items-center justify-center flex-shrink-0">
                            <span class="text-white text-sm font-bold">${turnCount}</span>
                        </div>
                        <div class="flex-1">
                            <p class="transcript-text text-white text-sm leading-relaxed">${escapeHtml(
                                text
                            )}</p>
                            <div class="flex items-center justify-between mt-2 pt-2 border-t border-green-400/20">
                                <span class="text-xs text-green-200/70">üé§ Turn Complete</span>
                                <span class="text-xs text-green-200/70">${new Date().toLocaleTimeString()}</span>
                            </div>
                        </div>
                    </div>
                </div>
            `;

                transcriptionContainer.appendChild(transcriptElement);

                // Scroll to bottom
                transcriptionContainer.scrollTop =
                    transcriptionContainer.scrollHeight;
            }

            function addSystemMessage(message, type = "info") {
                const messageElement = document.createElement("div");
                messageElement.className = "text-center my-4 animate-fadeIn";

                let bgClass, textClass, icon;
                switch (type) {
                    case "error":
                        bgClass = "bg-red-500/10 border-red-400/20";
                        textClass = "text-red-300";
                        icon = "‚ùå";
                        break;
                    case "success":
                        bgClass = "bg-green-500/10 border-green-400/20";
                        textClass = "text-green-300";
                        icon = "‚úÖ";
                        break;
                    default:
                        bgClass = "bg-blue-500/10 border-blue-400/20";
                        textClass = "text-blue-300";
                        icon = "‚ÑπÔ∏è";
                }

                messageElement.innerHTML = `
                <div class="inline-flex items-center gap-2 px-4 py-2 rounded-full ${bgClass} border backdrop-blur-sm ${textClass}">
                    <span>${icon}</span>
                    <span class="text-xs font-medium">${escapeHtml(
                        message
                    )}</span>
                </div>
            `;

                transcriptionContainer.appendChild(messageElement);
                transcriptionContainer.scrollTop =
                    transcriptionContainer.scrollHeight;
            }

            function escapeHtml(text) {
                const div = document.createElement("div");
                div.textContent = text;
                return div.innerHTML;
            }

            // Initialize on page load
            document.addEventListener("DOMContentLoaded", function () {
                console.log("Inline script loaded, initializing...");

                // Get DOM elements
                startBtn = document.getElementById("startBtn");
                stopBtn = document.getElementById("stopBtn");
                clearBtn = document.getElementById("clearBtn");
                connectionStatus = document.getElementById("connectionStatus");
                listeningStatus = document.getElementById("listeningStatus");
                realTimeStatus = document.getElementById("realTimeStatus");
                interimText = document.getElementById("interimText");
                transcriptionContainer = document.getElementById(
                    "transcriptionContainer"
                );

                console.log("Elements found:", {
                    startBtn: !!startBtn,
                    stopBtn: !!stopBtn,
                    clearBtn: !!clearBtn,
                    connectionStatus: !!connectionStatus,
                    realTimeStatus: !!realTimeStatus,
                    interimText: !!interimText,
                    transcriptionContainer: !!transcriptionContainer,
                });

                // Event listeners
                if (startBtn)
                    startBtn.addEventListener("click", startRecording);
                if (stopBtn) stopBtn.addEventListener("click", stopRecording);
                if (clearBtn)
                    clearBtn.addEventListener("click", clearTranscripts);

                console.log("Connecting to WebSocket...");
                // Connect WebSocket
                connectWebSocket();
            });
        </script>
    </body>
</html>
